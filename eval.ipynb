{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import os, yaml, json, requests\n",
    "import matplotlib.pyplot as plt\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
    "import tqdm, random\n",
    "import time\n",
    "import torch\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def show_single_img(img: Image):\n",
    "    plt.cla()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./example.jpg\"\n",
    "img = Image.open(img_path)\n",
    "show_single_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type='yolov8',\n",
    "    model_path=\"./models/best.pt\",\n",
    "    confidence_threshold=0.3,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "result = get_sliced_prediction(\n",
    "    img,\n",
    "    detection_model,\n",
    "    slice_height=640,\n",
    "    slice_width=640,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = result.object_prediction_list\n",
    "print(len(res_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.export_visuals(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor():\n",
    "\n",
    "    def __init__(self, model_path: str, conf=0.5):\n",
    "        self.detection_model = AutoDetectionModel.from_pretrained(\n",
    "            model_type='yolov8',\n",
    "            model_path=model_path,\n",
    "            confidence_threshold=conf,\n",
    "            device=\"cpu\",\n",
    "        )\n",
    "        self.model_name = model_path.split(\"/\")[-1][:-3]\n",
    "        self.img_path = \"./dataset/images/\"\n",
    "        self.lab_path = \"./dataset/labels/\"\n",
    "\n",
    "    def get_batches(self, num=10):\n",
    "        img_all = os.listdir(self.img_path)\n",
    "        batch_size = len(img_all) // num\n",
    "        print(\"num_images=\", len(img_all))\n",
    "        print(\"batch_size=\", batch_size)\n",
    "        print(\"batch_num=\", num)\n",
    "        random.shuffle(img_all)\n",
    "        for i in range(num):\n",
    "            yield img_all[i * batch_size:min(len(img_all), (i + 1) * batch_size)]\n",
    "\n",
    "    def predict_batch(self, img_list):\n",
    "        real = 0\n",
    "        pred = 0\n",
    "        # qbar = tqdm.tqdm(img_list)\n",
    "        # for img_name in qbar:\n",
    "        for img_name in img_list:\n",
    "            # qbar.set_description(f\"real={real}, pred={pred}\")\n",
    "            img_path_full = os.path.join(self.img_path, img_name)\n",
    "            result = get_sliced_prediction(\n",
    "                img_path_full,\n",
    "                self.detection_model,\n",
    "                slice_height=384,\n",
    "                slice_width=384,\n",
    "                overlap_height_ratio=0.2,\n",
    "                overlap_width_ratio=0.2,\n",
    "                verbose=0)\n",
    "            pred += len(result.object_prediction_list)\n",
    "\n",
    "            lab_path_full = os.path.join(self.lab_path, img_name.replace(\".jpg\", \".txt\"))\n",
    "            with open(lab_path_full, \"r\") as f:\n",
    "                real += len(f.readlines())\n",
    "        return real, pred\n",
    "\n",
    "    def predict_single(self, img_path_full):\n",
    "        return get_sliced_prediction(\n",
    "            img_path_full,\n",
    "            self.detection_model,\n",
    "            slice_height=384,\n",
    "            slice_width=384,\n",
    "            overlap_height_ratio=0.2,\n",
    "            overlap_width_ratio=0.2,\n",
    "            verbose=0)\n",
    "\n",
    "    def sahi(self, dates=[]):\n",
    "        path = \"./raw/\"\n",
    "        results = []\n",
    "        for data in dates:\n",
    "            path_full = os.path.join(path, data)\n",
    "            img_list = os.listdir(path_full)\n",
    "            result_single_day = []\n",
    "            qbar = tqdm.tqdm(range(0, len(img_list), 5))\n",
    "            for idx in qbar:\n",
    "                qbar.set_description(f\"date={data}, idx={idx}\")\n",
    "                img_list_batch = img_list[idx:idx + 5]\n",
    "                img_path_list = [os.path.join(path_full, img_name) for img_name in img_list_batch]\n",
    "                count_single_plant = []\n",
    "                for img in img_path_list:\n",
    "                    count_single_leaf = self.predict_single(img)\n",
    "                    count_single_plant.append(len(count_single_leaf.object_prediction_list))\n",
    "                \n",
    "                idx_plant = idx // 5\n",
    "                idx_leaf = idx % 5\n",
    "                result_single_plant = {\n",
    "                    \"plant_idx\": idx_plant,\n",
    "                    \"leaf_idx\": idx_leaf,\n",
    "                    \"count\": count_single_plant\n",
    "                }\n",
    "                result_single_day.append(result_single_plant)\n",
    "\n",
    "            results.append(result_single_day)\n",
    "            \n",
    "        return results \n",
    "\n",
    "\n",
    "    def work(self):\n",
    "        start_time = time.time()\n",
    "        batches = list(self.get_batches(num=100))\n",
    "        real_list = []\n",
    "        pred_list = []\n",
    "        qbar = tqdm.tqdm(range(len(batches)))\n",
    "        for batch_idx in qbar:\n",
    "            batch = batches[batch_idx]\n",
    "            qbar.set_description(f\"real={sum(real_list)}, pred={sum(pred_list)}\")\n",
    "            real, pred = self.predict_batch(batch)\n",
    "            real_list.append(real)\n",
    "            pred_list.append(pred)\n",
    "        self.results = {'real': real_list, \n",
    "                        'pred': pred_list}\n",
    "        self.time = time.time() - start_time\n",
    "        print(f\"Done in {self.time:.2f} sec!\")\n",
    "    \n",
    "    def save(self):\n",
    "        if not os.path.exists(\"./results/\"):\n",
    "            os.mkdir(\"./results/\")\n",
    "\n",
    "        results_file_name = f\"./results/results_{self.model_name}.json\"\n",
    "        with open(results_file_name, \"w\") as f:\n",
    "            f.write(json.dumps(self.results, indent=4, ensure_ascii=False))\n",
    "        print(f\"Results saved to {results_file_name}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(model_path=\"./models/best.pt\")\n",
    "predictor.work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.torch_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('./models/train4_best.pt')\n",
    "\n",
    "n_p = get_num_params(model)\n",
    "n_g = get_num_gradients(model)\n",
    "n_l = len(list(model.modules()))\n",
    "\n",
    "print(f\"{n_l} layers, {n_p} parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
